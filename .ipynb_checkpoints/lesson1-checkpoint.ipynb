{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to deep learning\n",
    "## MASTER CSA : Introduction to Embedded systems\n",
    "\n",
    "------------\n",
    "###### author : Geoffrey Roman Jimenez\n",
    "###### Date : 19/03/18\n",
    "\n",
    "*\"an overall of what is **deep learning**.\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "###### 1 - What is it ?\n",
    "\n",
    "\n",
    "**Deep-learning** is a branch of Machine-learning which is a type of Artificial intelligence. \n",
    "\n",
    "Machine-learning aimed at contruct algorithm that can performed a task without explicitly programming it to do so.\n",
    "\n",
    "- Machine-learning aimed at learning a task to a machine. \n",
    "    - **Deep-learning** aimed at doing the same\n",
    "\n",
    "**Deep-learning** is based on the *learning data representation* task. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### A task in data science\n",
    "\n",
    "1. **Data Classification/Clustering**\n",
    "    * Classify or regroup data (images for example) \n",
    "    <img src=\"./catdogclassification.jpg\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2. **Data Prediction/Regression**\n",
    "    * Modelling relationship between Data<br/> \n",
    "       <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Linear_regression.svg/1000px-Linear_regression.svg.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "3. **Data representation **\n",
    "    * `Dimension reduction, encodage`\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/2/28/Autoencoder_structure.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2 - How does it works\n",
    "\n",
    "### 2.1 - Artificial Neural (AN)\n",
    "<img src=\"neural.jpg\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "$$ y = \\mathcal N~(\\mathbf{x}, \\mathbf{w}, b) = \\varphi \\Bigg( \n",
    "\\begin{bmatrix}\n",
    "w_{1}   & \\dots  &   w_{n} \\\\\n",
    "\\end{bmatrix}\n",
    ".\n",
    "\\begin{bmatrix} x_1 \\\\ \\vdots \\\\ x_n \\end{bmatrix}  + \n",
    "b\n",
    "\\Bigg) = \\varphi \\Big( \\sum_{i}{x_i . w_i} ~~ + b\\Big)$$\n",
    "\n",
    "\n",
    "with $\\varphi$ is a non-linearity function such as $tanh$ or $relu$\n",
    "\n",
    "<img src=\"relu.png\" alt=\"Drawing\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.2 - Artificial Neural Network (ANN)\n",
    "\n",
    "#### 2.2.1 Linear Model Architecture (LMA) :  a network without hidden layer \n",
    "<img src=\"neuralnetwork_tiny.jpg\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "\n",
    "the output $ y $ can be written as:\n",
    "\n",
    "$ y = \n",
    "\\varphi \\Bigg( \n",
    "\\begin{bmatrix}\n",
    "w_{1}    &   w_{2} \\\\\n",
    "\\end{bmatrix}\n",
    ".\n",
    "\\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix}  + \n",
    "b\n",
    "\\Bigg)\n",
    "$\n",
    "\n",
    "which can be written in a more compact way\n",
    "\n",
    "\n",
    "$y = \\varphi ( \\mathbf W.\\mathbf x + b)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.2 - Artificial Neural Network (ANN)\n",
    "\n",
    "#### 2.2.2 Shallow Neural Network (SNN)  :  a network with one hidden layer\n",
    "\n",
    "<img src=\"neuralnetwork_small.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "\n",
    "the output $y$ can be written as:\n",
    "\n",
    "$y =\n",
    "\\begin{bmatrix}\n",
    "w_{out_1}       &   w_{out_2}  & w_{out_3}    \\\\ \n",
    "\\end{bmatrix}.\n",
    "\\varphi \\Bigg( \n",
    "\\begin{bmatrix}\n",
    "w_{in(1,1)}       &   w_{in(1,2)}        \\\\\n",
    "w_{in(2,1)}       &   w_{in(2,2)}      \\\\ \n",
    "w_{in(3,1)}       &   w_{in(3,2)}  \\\\\n",
    "\\end{bmatrix}.\n",
    "\\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix}  + \n",
    "\\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3 \\end{bmatrix} \n",
    "\\Bigg)+ b $\n",
    "\n",
    "Which can be written in a more compact way :\n",
    "\n",
    "$\\mathbf{y} = \\mathbf W_{out}. \\varphi ( \\mathbf W_{in}.\\mathbf x + \\mathbf b_{in}) + \\mathbf b_{out}$\n",
    "\n",
    "**Note**:\n",
    "*Unlike all layers in a Neural Network, the output layer neurons most commonly do not have an activation function (or you can think of them as having a linear identity activation function).*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "#### 2.2.1 A more deeper one \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[//]: # (![alt text](./neuralnetwork.jpg \"NeuralNetwork\"))\n",
    "<img src=\"neuralnetwork.jpg\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "\n",
    "${y}(\\mathbf{x}, {\\mathbf{\\mathcal W}}, \\mathbf{B}) = \\mathbf W_4 . \\varphi \\bigg( \\mathbf{W}_{3} . \\varphi \\Big( \\mathbf{W}_{2} . \\varphi (\\mathbf W_{1}.\\mathbf x + \\mathbf b_1) + \\mathbf{b}_2 \\big) + \\mathbf{b}_{3} \\Big) + {b}_{4}$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# More generally\n",
    "\n",
    "We can add as many inputs/layer/output as we want :\n",
    "\n",
    "<img src=\"neuralnetwork_large.jpg\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "\n",
    "So in a general way we have : \n",
    "\n",
    "$\\mathbf{y}(\\mathbf{x}, {\\mathbf{\\mathcal W}}, \\mathbf{B}) = \\mathbf W_d . \\varphi \\bigg( \\mathbf{W}_{d-1} . \\varphi \\Big( \\mathbf W_{d-2}  \\dots \n",
    "\\varphi \\big( \\mathbf{W}_{2} . \\varphi (\\mathbf W_{1}.\\mathbf x + \\mathbf b_1) + \\mathbf{b}_2 \\big) \\dots + \\mathbf{b}_{d-2} \\Big) + \\mathbf{b}_{d-1} \\bigg) + \\mathbf{b}_d$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$\\mathbf{y}(\\mathbf{x}, {\\mathbf{\\mathcal W}}, \\mathbf{B}) = \\mathbf W_d . \\varphi \\bigg( \\mathbf{W}_{d-1} . \\varphi \\Big( \\mathbf W_{d-2}  \\dots \n",
    "\\varphi \\big( \\mathbf{W}_{2} . \\varphi (\\mathbf W_{1}.\\mathbf x + \\mathbf b_1) + \\mathbf{b}_2 \\big) \\dots + \\mathbf{b}_{d-2} \\Big) + \\mathbf{b}_{d-1} \\bigg) + \\mathbf{b}_d$\n",
    "\n",
    "\n",
    "with \n",
    "\n",
    "$\\mathbf y  = \\begin{pmatrix} y_1 \\\\ y_2 \\\\ \\dots \\\\ y_{n_d}\\end{pmatrix}$\n",
    "and \n",
    "$\\mathbf x  = \\begin{pmatrix} x_1 \\\\ x_2 \\\\ \\dots \\\\ y_{n_0}\\end{pmatrix}$\n",
    "\n",
    "$\\mathcal W = \\{ \\mathbf W_1, \\mathbf W_2, ..., \\mathbf W_{d-1}, \\mathbf W_{d}\\}\n",
    "~~~~~~~~ \n",
    "and \n",
    "~~~~~~~~\n",
    "\\mathbf B = \\{ \\mathbf b_1, \\mathbf b_2, \\dots , \\mathbf b_{d-1}, \\mathbf b_d \\}$ \n",
    " \n",
    "$\n",
    "\\mathbf W_k = \\begin{pmatrix}\n",
    "w_{k(1,1)}       &   w_{k(1,2)}       & \\dots &   w_{k(1,n_{k-1})}       \\\\\n",
    "w_{k(2,1)}       &   w_{k(2,2)}       & \\dots &   w_{k(2,n_{k-1})}       \\\\\n",
    "\\vdots  &  \\vdots   &   \\vdots  & \\vdots  \\\\   \n",
    "w_{k(n_k,1)}       &   w_{k(n_k,2)}   & \\dots &   w_{k(n_k,n_{k-1})}  \\\\\n",
    "\\end{pmatrix}\n",
    "~~~~~~~ \n",
    "\\mathbf b_k = \\begin{pmatrix} b_1 \\\\ b_2 \\\\ \\vdots \\\\ b_{n_{k-1}} \\\\ b_{n_k} \\end{pmatrix}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Training an ANN\n",
    "\n",
    "So we have a model $\\mathbf{y}(\\mathbf{x}, {\\mathbf{\\mathcal W}}, \\mathbf{B})$.\n",
    "\n",
    "The parameters of this model are :  ${\\mathbf{\\mathcal W}}$ and $\\mathbf{B}$ \n",
    "\n",
    "\n",
    "\n",
    "### => Backpropagation algorithm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "http://playground.tensorflow.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.3 - Deep Neural Network (DNN)\n",
    "\n",
    "Deep Neural Network (DNN) is Artificial Neural Network with numerous hidden layers.\n",
    "\n",
    "<img src=\"https://indico.io/blog/wp-content/uploads/2015/08/googlenet.png\" alt=\"Drawing\" class=\"rotate90\" style=\"width: 600px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Third : Some examples\n",
    "\n",
    "\n",
    "![alt text](https://pjreddie.com/media/image/Screen_Shot_2016-11-26_at_11.22.46_PM.png \"YOLO\")\n",
    "\n",
    "http://scs.ryerson.ca/~aharley/vis/conv/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries importation\n",
    "import numpy\n",
    "import sys, os\n",
    "from IPython.display import HTML\n",
    "import tikzmagic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
